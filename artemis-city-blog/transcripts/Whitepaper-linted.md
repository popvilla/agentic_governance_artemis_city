# Artemis_City: A Novel Agentic Operating System Architecture

## Abstract
Artemis_City is presented as a new class of agentic operating system (AOS) designed for autonomous AI networks. It moves beyond conventional agent wrappers (e.g. AutoGPT, BabyAGI) by providing a full infrastructure-level architecture for managing multiple intelligent agents, persistent memory, and adaptive learning. Key innovations include an OS-like kernel for orchestration, a memory bus that integrates graph-based knowledge (Obsidian vault) with vector databases (Supabase), and a Hebbian learning engine enabling dynamic self-rewiring of knowledge links. Grounded in theories of embodied cognition, morphological computation, Hebbian plasticity, and cognitive morphogenesis, Artemis_City’s design facilitates emergent cognitive structures and robust long-term learning. This whitebook outlines the theoretical underpinnings, details the system architecture (kernel, registry, memory, governance, visual cortex), compares Artemis_City with existing agent frameworks, and charts a roadmap for future enhancements (reinforcement-driven routing, inhibitory control, memory decay, and plastic workflow adaptation). The aim is to establish Artemis_City as the foundation of a new generation of agentic intelligence infrastructure, combining academic rigor with a visionary blueprint for next-generation AI systems.

## Executive Summary
Artemis_City represents a paradigm shift from single-agent loop frameworks to a full-stack operating system for agentic AI. It is positioned as a new category of AI architecture that treats autonomous agents not as stand-alone instances but as orchestrated components of a larger cognitive ecosystem. The system introduces:
Core Innovations: An AOS kernel that schedules and manages agent processes (with dynamic role assignment and sandboxed execution), a memory bus that unifies file-based knowledge graphs and vector memory for both human-readable and machine-efficient recall, and a Hebbian plasticity module that continuously reorganizes knowledge based on experience.

### Theoretical Foundations:
Artemis_City’s design is inspired by embodied cognition (intelligence arising through interaction of mind, body, and environment), morphological computation (offloading computation to structure and environment[1]), and neuroplasticity principles (Hebbian learning: “neurons that fire together wire together” leading to strengthening of connections[2]). It embodies cognitive morphogenesis, allowing cognitive structures to self-assemble and evolve akin to biological development[3][4].

### Architecture Overview:
We detail how the Artemis_City Kernel orchestrates agent workflows and inter-agent communication, with an Agent Registry to manage agent lifecycles and sandboxing for safety. A Memory Bus connects agents to a hybrid memory: an Obsidian-based knowledge vault (graph of Markdown files capturing facts/relations)[5] and a Supabase vector store for efficient semantic lookup (leveraging Postgres pgvector for embeddings[6]). The knowledge vault forms a causal graph of experiences and insights, which the system updates via a Hebbian learning engine that strengthens useful associations and gradually prunes or weakens less useful ones (analogous to LTP/LTD from neuroscience[7]). A governance layer monitors agents via blocklists (for restricted actions/content) and scoring mechanisms to rate agent reliability, alignment, and performance over time. The system’s “Visual Cortex” presents an interactive graph view of the agents’ knowledge and connections, revealing an emergent topology of thoughts and memories as they form.

### Comparative Advantages:
Unlike AutoGPT or BabyAGI which wrap a single LLM in a feedback loop, Artemis_City provides multi-agent orchestration and persistent, structured memory. AutoGPT, for instance, has known issues with self-feedback loops and costly recursive calls, and struggles with long-term memory retention[8]. BabyAGI is adaptive but lacks robust integration and enterprise features[9]. Artemis_City addresses these gaps by offering a governed, explainable, and scalable framework: multiple specialized agents collaborate under a central OS, with shared context, monitoring, and alignment safeguards. It thereby shifts the focus from an agent’s isolated capabilities to the collective intelligence of an agent society, aligning with emerging best practices that stress orchestrating networks of agents rather than boosting a single agent[10][11].

### Future Roadmap:
The whitebook outlines planned enhancements including reinforcement-based routing (using feedback/rewards to dynamically route tasks or queries to the best-suited agent, analogous to MoE gating networks that route inputs to expert modules[12][13]), inhibitory control mechanisms (suppressing or pausing agents or thoughts that are detracting from goals, inspired by human executive function[14]), memory decay (gradual fading of stale information unless refreshed, to prevent knowledge bloat and simulate forgetting[7]), and plastic workflows that rewire the agent workflow graph itself based on learned improvements (allowing the system to evolve its problem-solving pathways over time). These additions aim to further emulate living cognitive systems where not just knowledge, but the entire decision-making process, remains plastic and self-optimizing.

In summary, Artemis_City is introduced as a foundational infrastructure for AGI research and deployment. It combines rigorous theoretical inspiration with an original architecture that transcends current agent frameworks. The following sections delve into each aspect in detail – from philosophy to implementation to future vision – to provide AGI researchers, cognitive systems engineers, and AI architects with a comprehensive understanding of Artemis_City’s design and its significance as a new milestone in agentic intelligence.
---

## Introduction and Positioning
Artificial General Intelligence research is increasingly focused on agentic AI systems – AI agents that can autonomously plan, perceive, act, and learn in open environments. Early demonstrations like AutoGPT and BabyAGI showed the promise of wrapping large language models (LLMs) in simple feedback loops to create autonomous agents, but they also highlighted limitations. These systems tend to operate as single monolithic agents and often suffer from lack of long-term memory, fragile self-referential loops, and poor scalability[8][9]. In contrast, Artemis_City is conceived as the genesis of a new category: an agentic operating system. This means providing the infrastructure and runtime environment for many specialized agents to coexist and collaborate, analogous to how a traditional operating system manages multiple processes.

### Distinct from Agent Wrappers:
Unlike agent wrappers that simply chain prompts to an LLM, Artemis_City introduces a comprehensive architecture with distinct layers and components for memory, learning, and governance. It rejects the notion that one LLM-based loop can handle all tasks; instead, it embraces a society of agents model where each agent has defined roles or specialties, and a kernel mediates their interactions. This positioning aligns with the industry’s shift noted by Gartner and others – that the frontier is moving from creating single smarter agents to orchestrating networks of agents working in concert[15][16]. Artemis_City acts as that orchestration layer, effectively an “AI operating system” that coordinates specialized agents with shared goals.

### Academic and Visionary Tone:
 In articulating Artemis_City, we draw parallels to the visionary technical roadmaps seen in seminal AI system papers. Just as DeepMind’s AlphaGo or OpenAI’s GPT-4 papers combined theoretical insight with system details, this whitebook aims to rigorously yet imaginatively present Artemis_City. We view it as the founding of a new class of AI infrastructure, where agent autonomy, continuous learning, and system-level governance are first-class design goals. By reading on, the technical audience will gain both an intellectual foundation (the “why” rooted in cognitive science and AI theory) and an engineering blueprint (the “how” in terms of modules and data flows) for Artemis_City.

Ultimately, Artemis_City’s introduction as a proprietary architecture is not merely about a single system, but about establishing a paradigm. It suggests that to approach human-like general intelligence, we must architect our AI at the infrastructure level, much like an operating system for cognition, rather than incremental tweaks to single-agent wrappers. The next sections first explore the philosophical underpinnings that guided this approach, before diving into the architecture itself in detail.

## Philosophical and Theoretical Underpinnings
Artemis_City’s design is deeply informed by several key theories in cognitive science and AI. These theories provide a philosophical compass for why the architecture is structured as it is. In this section, we outline four foundational concepts – embodied cognition, morphological computation, Hebbian plasticity, and cognitive morphogenesis – and discuss how each influences Artemis_City.

### Embodied Cognition
Traditional views of AI often treat cognition as abstract symbol manipulation divorced from any physical context. In contrast, embodied cognition argues that intelligence arises from the dynamic interaction between an agent’s mind, body, and environment[17]. Cognition is not just in the “brain” (or model weights), but is spread across sensory, motor, and environmental structures. Artemis_City embraces this by treating each agent not as a disembodied reasoning engine, but as an embodied process with its own state, tools, and environment sandbox. For example, an agent in Artemis_City may have a virtual “body” in the form of its accessible tools and knowledge scope, and its cognition emerges through interactions within those bounds.

In embodied cognition research, the term 4E cognition has been used – standing for embodied, embedded, enactive, extended cognition[18][19]. Artemis_City’s philosophy aligns with this: agents are embodied in that they have distinct contexts and can manipulate their (digital) environment; they are embedded in the larger system (situated in Artemis_City’s society of agents and memory); they are enactive by continually performing actions to learn (e.g. reading/writing to the memory graph, invoking tools); and they are extended via the shared memory and tools that become an extension of their mind. By grounding agent behavior in an environment (even if a simulated one), we allow phenomena like situational context, feedback from actions, and environment-induced constraints to shape the agent’s cognition. This is inspired by observations in cognitive science that intelligent behavior “emerges” from the loop of perception-action rather than from static planning alone[17].
In practical terms, Artemis_City’s architecture implements embodied cognition by providing agents with APIs to sense and effect changes in their world. The Visual Cortex (graph view) can be seen as a kind of sensory input – agents can “see” the state of the knowledge graph or the presence of other agents, rather than operating blindly. The sandboxing (discussed later) is akin to a body that limits what an agent can directly affect, ensuring safety. Through these design choices, the system acknowledges that where an agent “lives” and what it can touch are integral to how it learns and behaves, echoing the embodied paradigm.

### Morphological Computation
An equally important concept is morphological computation – the idea that an agent’s physical form or structure can carry out computation that would otherwise burden the brain or controller. In robotics and biology, this is seen when a body’s natural dynamics simplify control (a classic example: human leg tendons and muscles handle shock absorption and terrain adaptation partly on their own, reducing what the brain must compute for running[1][20]). In summary, morphological computation describes reducing the brain’s computational load by offloading tasks to the body and environment[1].

In Artemis_City, we interpret morphological computation in a digital sense. The “morphology” here is the architecture itself and the data structures. By structuring knowledge as a graph of linked notes and by having specialized agents, the system’s form is performing part of the computation. For instance, instead of one giant model internally sorting through all knowledge, the file-based graph structure offloads that organization to the data itself: relationships are explicit as links, meaning a query can be answered by simple graph traversal rather than heavy inference. The memory architecture thus acts like a morphological computer – its shape (graph topology) helps compute answers efficiently. Another example is how the kernel routing works: by having a registry of agents each with declared capabilities, the very existence of modular specialist agents means the system’s “body” (set of agents) is structured to handle complexity, rather than a single brain doing all tasks. Each agent can be thought of as a “limb” or “organ” in a body, processing certain inputs naturally well.

This principle leads to designing Artemis_City such that structure and computation co-evolve. We allow new agent modules to be added (changing the morphology of the agent society) to handle new types of problems, rather than overloading existing agents. Similarly, storing knowledge in human-readable Markdown files with links means that even outside the main neural components, the environment (file system + graph) itself is doing work to maintain associations. By exploiting structure, we follow the lesson from biology: the body (architecture) is part of the solution, not just part of the problem[1][20]. This yields an AI OS where complex behavior emerges from the interplay of simple parts configured in a clever way – the hallmark of morphological computation.

### Hebbian Plasticity (Neuroplasticity Principles)
At the heart of Artemis_City’s learning engine is a homage to Donald Hebb’s famous principle: “cells that fire together, wire together.” Hebbian learning, originally a theory of how synapses strengthen in the brain, has become a guiding rule for self-organizing networks. In plain terms, if two pieces of information are activated or used in tandem frequently, the connection between them should become stronger[2]. Artemis_City implements this via a Hebbian plasticity engine that operates on the knowledge graph and other internal representations.

Concretely, each time agents produce a successful reasoning chain or solve a problem, the relationships between the knowledge nodes and agent actions involved in that success are reinforced. The memory graph’s links have weights that increase when the linked concepts are used together productively, analogous to long-term potentiation (LTP) in neurons[7]. If certain connections go unused or lead to failures, weights may decay – analogous to long-term depression (LTD) where synaptic connections weaken over time without reinforcement[7]. By formalizing these operations, Artemis_City ensures that its memory isn’t static; it adapts based on usage, highlighting useful paths and dimming irrelevant ones. This is essential for an agentic system to improve over time rather than repeating mistakes or forgetting important context.

A key twist we incorporate is validation-gated Hebbian learning. A known challenge in autonomous LLM agents is hallucination or reinforcing incorrect info. Inspired by recent research[21], Artemis_City’s Hebbian updates occur only when outcomes pass certain quality checks. For example, if two pieces of information co-occur in an agent’s reasoning but lead to a wrong answer or factual error, the system can detect that (via a governance agent or fact-check tool) and avoid strengthening that link – thereby not “learning” a mistake. Only when a reasoning path is successful and validated do we consolidate it as a stronger connection in the knowledge base. This approach is akin to having an internal critic or “immune system” for memory formation, preventing hallucination reinforcement[21]. It parallels how a brain might not form long-term memories from dreams or illusions, focusing on consistent reality instead.

The outcome of incorporating Hebbian plasticity is a memory that exhibits use-dependent organization. Frequently accessed knowledge becomes highly connected and readily accessible; new concepts initially attach loosely and either strengthen as they prove useful or fade if they remain unused. Over time, Artemis_City’s knowledge topology shapes itself to mirror what is effective or true in the agent’s experience, which is a step beyond static vector databases or knowledge graphs. As one researcher aptly put it, “Memory without reorganization is just a database”[22]. Artemis_City strives for a living memory that continuously reshapes itself, which we believe is crucial for reaching higher-order general intelligence.

### Cognitive Morphogenesis
The term cognitive morphogenesis can be thought of as the developmental growth of cognitive structures, analogous to how a simple embryo develops into a complex organism (morphogenesis in biology). Recent work in theoretical biology and AI suggests uniting embryological development concepts with cognitive science, viewing cognitive architecture growth as a kind of self-organizing morphogenetic process[23][3]. In an AI context, this means the system’s cognitive structure (its agents, memory networks, skill modules) can start from a simple state and differentiate into specialized subsystems over time.

Artemis_City is explicitly designed to support cognitive morphogenesis. In the beginning, an instance of Artemis_City might start with only a few generic agents and minimal knowledge. As it operates, it can spawn new specialized agents (akin to cells differentiating into new tissue types) when needed – for example, if a particular type of task keeps recurring, a new agent specialized in that domain can be added to the registry. The knowledge graph can similarly branch out: core facts form the “zygote” of knowledge, and as new information comes in, the graph branches into clusters or “tissues” of related knowledge, linked by context. This process is reminiscent of the differentiation trees discussed by Alicea et al. (2023), where an initial undifferentiated cognitive substrate splits into specialized subsystems through symmetry-breaking events[3][4]. In Artemis_City, every time we add a new agent or a new high-level memory cluster, we are performing a form of symmetry breaking – introducing asymmetry that allows new capabilities to emerge.

Researchers observing embodied cognitive morphogenesis note properties like acquisition, generativity, and transformation as hallmarks of the process[24]. Artemis_City exhibits these: acquisition through continuous learning and memory growth; generativity by producing new solutions, plans, or even new internal agents from its base elements; and transformation by reorganizing its internal structures (both memory links via Hebbian learning and workflow structures via meta-learning). The concept of connectogenesis[4] – the formation of new connections – is literally implemented in our causal graph whenever an agent finds a novel relation between two concepts and links them. Over time, the system’s cognitive “anatomy” becomes richer and more complex, not by explicit programming, but by self-directed evolution.

This perspective frames Artemis_City not as a static designed system, but as a growing cognitive organism. Its architecture facilitates growth: modularity allows parts to be added, the Hebbian engine allows internal re-wiring, and governance ensures it grows in desirable directions (much like biological growth has genetic regulation). By treating the development of AI intelligence as a morphogenetic process, we position Artemis_City to potentially scale towards higher complexity in a controlled way – new skills and knowledge emerging from old, rather than requiring complete redesigns. In summary, cognitive morphogenesis in Artemis_City means continuous self-construction: the system builds itself up iteratively, which could be essential for reaching human-level adaptability and open-ended learning.

Having established the theoretical motivations behind Artemis_City, we now transition into the architecture itself. We will see how these principles – embodiment, structure-exploiting computation, plasticity, and self-organization – are concretely realized in the system’s components and data flows.

## Detailed Architecture
The Artemis_City architecture is organized into several core components, each responsible for a facet of the system’s overall intelligence. In this section, we break down the architecture into logical sections: the Kernel and Orchestration Flow, the Agent Registry and Sandboxing mechanisms, the Memory Bus including the Obsidian-based graph and Supabase vector store, the File-based Causal Graph representation of knowledge, the Hebbian Learning Engine that adapts this knowledge base, the Agent Governance subsystem with blocklists and scoring, and the Visual Cortex which provides a graph-based visualization and interface. Each subsection details the design and function of these components, and how they interrelate in the operation of Artemis_City.

### Kernel Structure and Orchestration Flow
At the heart of Artemis_City is the Kernel, a central orchestrator analogous to an operating system kernel. The kernel is responsible for scheduling tasks, routing communications, and managing resources among the various agents. When an input or goal enters Artemis_City (e.g., a user query or an autonomous objective), the kernel decides how to break this down and which agents should handle which parts. This design follows a multi-agent orchestration approach where the emphasis is on coordination. As the Kore.ai analysis noted, “orchestration transforms AI into a coherent, governed, and future-ready capability”[11], ensuring specialized agents integrate rather than collide.

#### Architecture:
 The kernel maintains a global state including a common context that agents can read and write to (this forms part of the memory bus, described later). It uses an event-driven loop: each agent can emit events (e.g., “subtask completed” or “new data ingested”) and subscribe to events (e.g., “need analysis” or “conflict detected”). The kernel listens for events and invokes the appropriate agent or set of agents in response. For example, if an agent responsible for web browsing finishes gathering information, it might emit an event that triggers a summarizer agent to process that information. The orchestration flow can be sequential or parallel depending on the situation. Artemis_City can implement patterns such as: sequential pipelines (agent A’s output goes to agent B, etc.), concurrent agents (multiple agents work in parallel on the same problem and results are merged), or adaptive routing (the next agent is chosen based on intermediate results). These align with known multi-agent patterns like those documented by Microsoft’s Azure guide (sequential vs concurrent orchestration)[25][26], though Artemis_City can dynamically switch patterns if needed, making it very flexible.

A simple orchestration example: Suppose Artemis_City is tasked with answering a complex research question. The kernel might start an Researcher Agent to gather data, a Analyst Agent to interpret that data, and a Writer Agent to compose the final answer. It may run Researcher and Analyst concurrently if they can work in parallel on different subtopics, then collect their outputs. The kernel ensures that shared memory is updated and that each agent sees the up-to-date context. The orchestration also involves conflict resolution – if two agents produce inconsistent results, the kernel can invoke a Evaluator Agent to assess which is more credible, or even spawn a new agent to reconcile differences. This echoes the dynamic role allocation and conflict resolution capabilities identified as essential in multi-agent systems[27][28].
Flow Control: Artemis_City’s kernel uses a combination of static plans and dynamic decision-making. Some workflows are pre-defined (especially for common tasks, to optimize performance), but the kernel can also make on-the-fly decisions. A governance rule might be: if a task is taking too long with current agents, spawn a helper agent or escalate to a human. These rules are part of the kernel’s policy. Importantly, because our agents may be learning and the system state evolving, the kernel itself can utilize meta-learning – adjusting its scheduling strategies over time as it observes which orchestrations work best. Thus, the kernel is not a fixed algorithm but a semi-adaptive coordinator that is continually tuned through experience.

In summary, the Artemis_City kernel is the central brain stem of the architecture: it doesn’t do the heavy cognitive work (the specialized agents do that), but it ensures all parts function in unison, much like a conductor of an orchestra. This kernel-centric design differentiates Artemis_City from more naive agent wrappers by introducing a robust, modular backbone that can scale to enterprise needs (multiple simultaneous tasks, dozens of agents, real-time responses) while maintaining control and oversight.

### Agent Registry and Sandboxing
All agents in Artemis_City are registered in a centralized Agent Registry. The registry is essentially a directory of available agents, each with metadata including its capabilities (what tools or knowledge domains it has), its trust level or score, and its current status (idle, busy, quarantined, etc.). When the kernel needs to assign a task, it consults the registry to find suitable agents or to instantiate new ones if needed. This design allows agents to be plug-and-play – one can add a new agent (for example, a financial analysis agent) to the registry and immediately the kernel can start utilizing it when relevant tasks arise.

Sandboxing: With great power comes great responsibility – having autonomous agents demands caution. Artemis_City employs sandboxing techniques to ensure that agents operate within bounds. Each agent runs in a constrained environment where its access to external systems (files, network, APIs) is mediated by the kernel’s permission system. By default, agents can only interact with the world through the interfaces Artemis_City provides (e.g., memory bus, approved tools). If an agent tries to perform an action outside its scope, the kernel intercepts it. This prevents errant or malicious behavior from causing harm. It’s similar to how mobile apps are sandboxed on modern operating systems, or how web browsers sandbox scripts.

One application of sandboxing in our context is for ethics and safety testing. We can run new or modified agents in a simulated environment first – effectively a sandbox mode – before deploying them on real tasks. As IBM’s AI governance guidelines suggest, “AI sandboxing allows developers to study unintended ethical dilemmas before exposing agents to real users”[29]. Artemis_City can simulate certain scenarios (for instance, through test queries or dummy data) to observe how an agent behaves. If it violates any rules or shows problematic behavior, it can be refined or blocked. The Agent Registry might mark such an agent as “quarantined” so the kernel will not assign it real tasks until approved.

Governance Agents: An interesting innovation we include is the notion of governance agents or watchdogs. These are special agents whose role is to monitor other agents’ outputs and interactions. They operate within the same system but have elevated monitoring privileges instead of domain task skills. As IBM experts muse, working agents could be paired with “governance agents designed to monitor and evaluate other agents,” acting like a hall monitor to catch anomalies[30]. In Artemis_City, a governance agent might scan all messages an agent sends to the memory or to external APIs, checking for compliance (no leaking of sensitive data, no disallowed content) and quality (is it making sense, is it factual?). If something is off, the governance agent can flag it to the kernel, which can then intervene – possibly pausing the agent, resetting it, or requiring a human operator to approve the next step. This layered approach means Artemis_City is not just powerful, but safe and controllable.

Agent Scoring: The registry maintains a score or reputation for each agent. This score is updated based on performance metrics – success rate of tasks, accuracy of outputs, alignment with instructions, etc. Over time, the kernel can use these scores to bias routing of tasks to more reliable agents. It’s analogous to how one might trust an experienced employee over a new hire for critical tasks. Additionally, metrics like context relevance, factual accuracy, response quality could be tracked per agent, similar to how IBM’s governance tooling is integrating specialized metrics (like context relevance, faithfulness) to monitor agent performance[31]. Artemis_City leverages these scores in decision-making: for example, if an agent with a low alignment score attempts an action that could be sensitive, the system might require a higher threshold of validation or switch to a backup agent.
In effect, the Agent Registry and Sandboxing layer enforce a principle of least privilege and accountability: agents only do what they are permitted and qualified to do, their actions are transparent to oversight modules, and their past behavior influences their future authority. This design ensures that even as we scale up to many agents, possibly with different creators or versions, the overall system stays robust against individual failures and aligned with its governing policies.

### Memory Bus: Obsidian Vault and Supabase Vector Store
Artemis_City employs a hybrid memory system to serve both the precision of structured knowledge and the breadth of neural embeddings. We call this unified memory interface the Memory Bus, as it acts like a data backbone to which all agents connect. The memory bus comprises two primary components: an Obsidian Vault (a collection of Markdown files forming a knowledge base) and a Supabase Vector Database (for fast similarity search and recall). Together, they provide the agents with both a human-like memory (notes and links) and a machine-like memory (dense vectors for semantic search).

Obsidian Vault (File-based Knowledge Graph): Obsidian is a popular knowledge management tool that stores notes as Markdown files with wiki-style links. Artemis_City uses an Obsidian-compatible format for its internal knowledge repository. Each concept, entity, or persistent memory is stored as a Markdown file (for example, Project_X.md might contain notes about Project X). Relations between notes are represented by hyperlinks (e.g., [[Project_X]] mentioned in Idea_Y.md to denote a connection). This effectively forms a knowledge graph where files are nodes and links are edges. The Obsidian graph view provides a visualization of this network[5][32]. The benefit of this approach is that the knowledge is explicit and interpretable – not just to the AI, but to human developers or analysts who can open the vault and inspect what the AI “knows” about something. It also allows leveraging a rich ecosystem of Obsidian plugins or tools for things like search, version control, etc.
To illustrate, suppose the system learns a new fact: “Artemis_City was deployed in a financial simulation on Jan 1, 2026.” This could be stored in a note Artemis_City_Deployment.md with content about that event, and linked to other relevant notes like Financial_Simulation.md and Timeline.md. In graph view, a user (or an agent) would see the Artemis_City node connected to nodes for the simulation and timeline, giving context. This file-based memory supports causality and chronology as well – an agent can write an “Observation” section under a note with time-stamped notes, effectively giving a chain of events. Indeed, the Obsidian Memory plugin documentation describes storing AI conversation memories as Markdown with YAML timestamps and links, so that “each entity is stored as a Markdown file” and relationships are captured via [[link]] syntax for graph visualization[33][34]. Artemis_City builds upon this concept, extending it beyond chat memories to all forms of knowledge the agents acquire.

Supabase Vector Store: While the Obsidian vault is great for structured knowledge and human readability, it’s not optimized for fuzzy recall or large document similarity search. That’s where the Supabase component comes in. Supabase (with its Postgres + pgvector) acts as a vector database, where embeddings of text or images can be stored and queried. Whenever an agent reads a document or processes a chunk of text, Artemis_City can generate an embedding (using an LLM or embedding model) and store it in the Supabase vector index along with metadata (which note it came from, or which agent/context). Then, when an agent needs to remember something semantically similar, it can query this store by vector similarity, retrieving possibly relevant info even if exact keywords differ. Supabase’s AI toolkit explicitly supports storing and indexing embeddings for such AI applications[6], making it a fitting choice.

For example, if an agent is asked a question that wasn’t seen before but is semantically close to a previous question, a vector search in memory might surface the prior answer or note as relevant context. This addresses the context-length limitations of LLMs by having an external long-term memory that can be searched. Additionally, Supabase can serve as a scalable, persistent backend that multiple Artemis_City instances could share or sync with (useful in distributed deployments). The memory bus would coordinate consistency between the Obsidian vault and the Supabase store – for instance, each time a Markdown note is created or updated, any significant text content is embedded and upserted to the vector DB; conversely, if new data comes via vector search, an agent might choose to write a corresponding note to make it explicit.

Memory Access Patterns: Agents can access memory through unified APIs. They can query for specific notes (structured query: “open node X”), search for text in notes (keyword search or regex across Markdown), or do semantic search (which goes to Supabase). The memory bus ensures these queries are served efficiently. For instance, a search_nodes query might look for a term across note titles[35], whereas a vector query might be an embedding lookup for the query text. The bus might first try an exact note lookup (for speed), then a fuzzy text search, then a vector search as fallback – blending precision and recall.

Causal and Contextual Linking: One special aspect of our memory design is emphasizing causal links. Beyond simple hyperlinks, Artemis_City supports typed links such as [[causes::]] or [[subtask_of::]] etc., to mark specific relationships. These are stored in the Markdown (as some in the Obsidian community do with “link types” or via attributes) and allow the graph to represent not just associations but directed relationships (e.g., Task A -> Task B in sequence, or Fact X leads to Conclusion Y). Such causal graph representation can enable reasoning algorithms to traverse “why” and “how” paths, not just “what” relates to what. It’s an area of active development, taking inspiration from “autobiographical causality” in memory research[36] – where experiences are stored with cause-effect links. In Artemis_City, if an agent infers that “X implies Y”, it can record that as a link in memory, effectively building a knowledge graph with reasoning traces. Future query answering can then leverage these without having to rediscover them from scratch.

In sum, the Memory Bus provides both brains of the operation: one symbolic/graphical and one sub-symbolic/distributed. This dual system is analogous to how humans have an explicit declarative memory (facts we can state) and a more associative memory (patterns we just recognize). By combining them, Artemis_City agents can retrieve precise information when needed, but also benefit from broad pattern matching when dealing with novel inputs.

## File-Based Causal Graph Representation
As hinted above, Artemis_City’s internal knowledge is structured as a causal graph encoded in a file system. This is not a generic knowledge graph of triples as in semantic web, but a purpose-built representation tailored to capturing cause-effect, dependency, and influence relationships among pieces of information and agent actions. We devote a section to this because it is a distinguishing feature of Artemis_City – the system doesn’t just accumulate data; it organizes it in a way that mirrors the logical and temporal structure of its experience.

Each Markdown file in the Obsidian vault can be seen as a node in a graph. The content of the file holds properties or a narrative about that node, and any link to another file denotes an edge. We enrich this basic model by allowing edges to carry semantics (via link labels). For example, a note “Investigation_42” might have a line stating - [[Investigation_41]] -> Outcome influenced this to indicate the prior investigation influenced the current one. Or - [[UserQuery123]] causes [[AgentPlan123]] to link a user query node to an agent’s plan node as cause and effect. By using a simple arrow notation or attributes, these get rendered in Obsidian as links (for human viewing) and parsed by Artemis_City’s memory manager as a directed edge with type.

The result is a rich graph where some subgraphs represent, say, a chain of reasoning or a sequence of events. When an agent forms a plan comprising steps A, B, C, the system could create a “plan node” that links to step A node, which in turn links to step B, etc., creating a chain. If step B fails, an annotation might link that event to the plan node as well (“Plan failed because B failed”). All this contextual information is stored in files, meaning it’s transparent and auditable.
This approach yields several benefits: - Traceability: We can trace why a certain decision was made by following the graph links backward (e.g., this conclusion node is linked from these evidence nodes, etc.). It serves as an explanation framework. - Incremental Learning: As new knowledge arrives, we add nodes and links. It’s easy to do partial updates (just add a file or a link) without retraining a whole model. The graph can grow indefinitely, unlike an LLM’s fixed context window. - Conflict Detection: If two contradictory nodes exist (e.g., one says “X happened” another says “X did not happen”), a governance agent or the reasoning algorithm can notice that by traversing and seeing inconsistent edges. This might prompt a resolution step (flagging for review or having a debate between agents). - Emergent Structure: Over time, the graph’s topology itself may reveal insights. We might see clusters form around certain topics, or certain nodes becoming hubs (highly connected). This emergent topology is effectively the “shape” of the AI’s knowledge. Researchers have noted that in self-organizing memory systems, “dimensional structure emerges rather than being engineered”[37]. Artemis_City embraces that: we set basic rules for linking, but we allow the network to self-organize as it grows. In the Visual Cortex section, we’ll discuss how we visualize and interpret this emergent graph.

To maintain performance, this file-based graph is supplemented by indexing (for example, the Supabase vector store to quickly find relevant nodes, as already described). But once a set of relevant nodes is identified, the graph can be traversed in-memory or via a graph database approach for complex queries (we could integrate a graph database if needed, but Markdown plus some in-memory graph structure may suffice for now). A formal way to define the knowledge graph is: G = (V, E, λ) where V is the set of Markdown files (nodes), E is the set of directed edges, and λ: E -> L is a labeling function mapping each edge to a relation type (drawn from a set L of possible link types, e.g., {causes, implies, contradicts, part_of, etc.}).
Each node v ∈ V carries data (the content of the file, which could include text, lists of observations, etc.). The causal graph specifically is the subgraph of G where λ(e) indicates a causal or temporal relation (like leads_to, causes, precedes). We might maintain separate adjacency lists for causal edges versus general associative links.Agents interacting with the graph typically don’t do arbitrary graph algorithms, but rather follow paths relevant to their task: e.g., a reasoning agent might do a depth-first traversal from a question node through cause-effect edges to gather supporting info. Another might do a breadth-first search around a concept to get related context. The design challenge is ensuring the graph doesn’t become too densely connected to be useful (hence the need for Hebbian pruning and keeping it coherent).

In conclusion, the file-based causal graph is Artemis_City’s way of structuring knowledge in a meaningful way. Instead of an opaque memory or a bag of texts, we have a living network of information. It reflects not just what the system knows, but how those pieces of knowledge interrelate. This structure is critical for advanced reasoning and is a core differentiator of Artemis_City’s architecture.

## Hebbian Learning Engine
Building on the earlier discussion of Hebbian plasticity in theory, here we describe the implementation and role of the Hebbian Learning Engine within Artemis_City. This engine continuously processes the activity and updates within the system to adjust the strengths of connections in the knowledge graph (and potentially the parameters of agents, if they have learning components), ensuring that the system’s performance improves over time through use.
Mechanisms: The Hebbian engine monitors co-activations in the system. Co-activation can mean several things in our context: - Two knowledge nodes frequently referenced together in successful problem solving. - An agent repeatedly following a particular sequence of steps that yield good results. - A particular question and a particular answer that consistently go together.Whenever such patterns are detected, the engine applies a weight update. If we denote w(i,j) as the weight of the link between node i and j, a simple rule is: Δw(i,j)=η⋅a_i⋅a_j, where a_i,a_j represent the activation (or some measure of importance) of nodes i and j in a given successful episode, and η is a learning rate. This is a mathematical way of saying: if i and j are active together, increase the weight connecting them[38]. In practice, the engine might give a small boost to the link every time they co-occur in a solution. Conversely, for decay, we might slightly decrease weights for links that haven’t been used in a long time, or if an attempted usage led to failure (negative reinforcement). These operations correspond to what Kairos et al. formalized as LTP and LTD analogues in adaptive knowledge graphs[7].

Validation Gate: Not all co-activations are good – sometimes two pieces of misinformation could co-occur and we don’t want to reinforce that. Therefore, Artemis_City’s Hebbian engine is validation-gated. It listens to signals from governance and validation agents or modules about the outcome quality. If a reasoning chain passes multi-dimensional quality checks (logical consistency, factual grounding, no policy violations), only then are the connections involved reinforced[21]. If the outcome was poor, the connections might instead be left unchanged or even slightly penalized. This ensures, for example, that if an agent happened to use a wrong formula and got a wrong answer, the system doesn’t mistakenly “learn” that wrong formula as a useful path. In essence, the Hebbian learning in Artemis_City is not unsupervised Hebb’s rule in the wild; it’s augmented with an error feedback loop to guard against garbage in, garbage out.

Scope of Plasticity: The primary locus of Hebbian updates is the knowledge graph (adjusting link weights), but it could also influence agent configurations. For instance, if two agents often work together successfully (say a ResearchAgent frequently feeding a SummaryAgent), the system could strengthen the association between those agents – e.g., biasing the kernel to pair them or even merging them into a pipeline. Likewise, if an agent’s certain internal rule or prompt seems to always trigger good responses, the agent’s internal parameters might adapt (assuming the agent supports learning; if not, Artemis_City might note this externally). However, since many agents might be stateless LLM calls, the main adaptation happens at the system level (in memory and orchestration) rather than within the black-box of an LLM.

<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js" charset="utf-8"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js" charset="utf-8"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
